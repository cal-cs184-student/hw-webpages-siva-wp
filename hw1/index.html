<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Siva Tanikonda</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-siva-wp/hw1/index.html">cal-cs184-student.github.io/hw-webpages-siva-wp/hw1/index.html</a>
		
		<br>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw1-siva-tanikonda">github.com/cal-cs184-student/sp25-hw1-siva-tanikonda</a>

		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.

		<h2>Task 1: Drawing Single-Color Triangles</h2>
		<ol>
			<li>The first step to rasterize a triangle was to find the coordinates and bounds of the bounding box. This is done by getting the minimum and maximum \(x\)-values and \(y\)-values of the triangle vertices. Then, I loop through every half-point within the bounding box. For each of these points \((i,j)\), I used the three-line test to check which side of each triangle line the point was on. For each triangle line from point \((x_0,y_0)\) to \((x_1,y_1)\), I calculated \(L=-(x-x_0)(y_1-y_0)+(y-y_0)(x_1-x_0)\). \(L=0\) means that the point is on the line, \(L<0\) means that the point is to the right of the line, and \(L>0\) means that the point is to the left of the line (we are assuming that this line is directed). As long as all points are not to the left, or all points are not to the right (i.e. the side is the same for every point with respect to all three sides of the triangle), then we know that our point is within the triangle. The disregard for whether all points are to the left or right allows us to deal with clockwise and counter-clockwise orderings and since points lying on a line will guaranteed be added (because our condition doesn't require the point to be stricly to the left or right), we handle points on edges properly. Then, for each sampled point in our triangle, we fill the pixel with our desired color.</li>
			<li>Since I am looping through only points within the bounding box in one-pixel increments, I only look at at most \(\mathcal{O}(B)\) points (where \(B\) is the number of pixels in the bounding box). Then, we perform simple multiplications/additions/subtractions to check if each point is within the triangle (which takes \(\mathcal{O}(1)\) time).</li>
			<li>Here is a screenshot of <code>basic/test4.svg</code> from my rendering:</li>
			<figure>
				<img src="test4.png" alt="Test 4" style="width:50%"/>
				<figcaption>Even with edge detection, the thin corners of some triangles have breaks in them.</figcaption>
			</figure>
			<li><strong>Extra Credit</strong>: here are some things I ended-up changing/optimizing when trying to improve my naive triangle rasterization algorithm (the above image was rendered with the optimized version, and the previous conceptual questions were answered based on the naive algorithm before the extra credit optimizations):
				<ul>
					<li>Reduced memory access: previously, I created two new functions: <code>calculate_l</code> and <code>point_in_triangle</code> to check the side of a line a point was on and check if a point was in a triangle, respectively. I consolidated these two functions so all the functionality is in <code>point_in_triangle</code>. This cut my runtime in half (<code>~75 -> ~37</code> milliseconds).</li>
					<li>Reducing search space: On each row of the triangle, I made it so that once we find a point that is no longer in the triangle, but the previous point was in the triangle, we know that all later points must not be in the triangle. This means I can just move on to the next row of the triangle without checking later pixels on the current row of the triangle. This cut my runtime by around a half again (<code>~37 -> ~20</code> milliseconds).</li>
				</ul>
				Before these optimizations, rendering <code>hardcore/01_degenerate_square1.svg</code> took <code>~75</code> milliseconds (according to <code>chrono::high_resolution_clock</code>). After the optimizations, the rendering took <code>~20</code> milliseconds. Here is the code before the optimization:
				<pre><code>
					float RasterizerImp::calculate_l(float x0, float y0, float x1, float y1, float x, float y) {
						int value = -(x - x0) * (y1 - y0) + (y - y0) * (x1 - x0);
						return value;
					}
					
					bool RasterizerImp::point_in_triangle(float x0, float y0, float x1, float y1, float x2, float y2, float x, float y) {
						float v1 = calculate_l(x0, y0, x1, y1, x, y);
						float v2 = calculate_l(x1, y1, x2, y2, x, y);
						float v3 = calculate_l(x2, y2, x0, y0, x, y);
						return ((v1 <= 0 && v2 <= 0 && v3 <= 0) || (v1 >= 0 && v2 >= 0 && v3 >= 0));
					}
					
					void RasterizerImp::rasterize_triangle(float x0, float y0, float x1, float y1, float x2, float y2, Color color) {
						float min_x = floor(min(x0, min(x1, x2)));
						float max_x = ceil(max(x0, max(x1, x2)));
						float min_y = floor(min(y0, min(y1, y2)));
						float max_y = ceil(max(y0, max(y1, y2)));
						for (float i = min_x + 0.5; i <= max_x; i++) {
						  	for (float j = min_y + 0.5; j <= max_y; j++) {
								if (point_in_triangle(x0, y0, x1, y1, x2, y2, i, j)) {
							  		rasterize_point(i, j, color);
								}
						  	}
						}
					}
				</code></pre>
				and after the optimization:
				<pre><code>
					bool RasterizerImp::point_in_triangle(float x0, float y0, float x1, float y1, float x2, float y2, float x, float y) {
						float v1 = -(x - x0) * (y1 - y0) + (y - y0) * (x1 - x0);
						float v2 = -(x - x1) * (y2 - y1) + (y - y1) * (x2 - x1);
						float v3 = -(x - x2) * (y0 - y2) + (y - y2) * (x0 - x2);
						return ((v1 <= 0 && v2 <= 0 && v3 <= 0) || (v1 >= 0 && v2 >= 0 && v3 >= 0));
					}
					
					void RasterizerImp::rasterize_triangle(float x0, float y0, float x1, float y1, float x2, float y2, Color color) {
						float max_x = ceil(max(x0, max(x1, x2)));
						float min_y = floor(min(y0, min(y1, y2)));
						float max_y = ceil(max(y0, max(y1, y2)));
						for (float i = floor(min(x0, min(x1, x2))) + 0.5; i <= max_x; i++) {
							bool in_triangle = false;
							for (float j = min_y + 0.5; j <= max_y; j++) {
								if (point_in_triangle(x0, y0, x1, y1, x2, y2, i, j)) {
									rasterize_point(i, j, color);
									in_triangle = true;
								} else if (in_triangle) {
									break;
								}
							}
						}
					}
				</code></pre>
			</li>
		</ol>
		
		<h2>Task 2: Antialiasing by Supersampling</h2>
		<ol>
			<li>To implement supersampling, I first expanded the sample buffer to be <code>sample_rate</code> times the size it originally was (i.e. each pixel has a <code>sqrt(sample_rate)*sqrt(sample_rate)</code> square of samples to determine its color). Then, for sampling each triangle, I up-scaled every coordinate of the triangle by <code>sqrt(sample_rate)</code> (this allows me to take <code>sample_rate</code> times as many samples of the triangle). Then, I updated the <code>fill_pixel()</code> function to index into the sample buffer based on these up-scaled coordinated passed in from the triangle rasterization function. To avoid super-sampling for lines and points, I added a new optional boolean parameter to the pixel rasterization and line rasterization functions that states if we are performing supersampling or not (the default value is <code>false</code> and when supersampling is disabled, the <code>fill_pixel()</code> function treats the input coordinates as being "un-scaled", and creates <code>sample_rate</code> duplicate samples to put for the single pixel, thus ensuring that averaging doesn't affect the final color of the pixel). I also updated the <code>set_sample_rate()</code> and <code>set_framebuffer_target()</code> functions to account for the <code>sample_rate</code> when creating the <code>sample_buffer</code>. Then, in <code>resolve_to_framebuffer()</code>, I made it so each pixel in <code>rgb_framebuffer_target</code> is the average of the colors of the <code>sample_rate</code> number of representative samples.</li>
			<li>The screenshots of the supersampling with different sample rates are below. The reason for the improvement in the clarity of thin parts of the image (such as corners) is that even if one of our samples is slightly off the edge of the triangle, the pixel that the sample represents will still not be white, because some samples of the pixel are non-white/in the triangle. This allows for more clarity for fine details in an image without issues such as breaks in the corner of the triangle due to unlucky sample positions with a low sample rate.</li>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="supersample1.png" width="400px"/>
							<figcaption><code>sample_rate=1</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="supersample4.png" width="400px"/>
							<figcaption><code>sample_rate=4</code></figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="supersample9.png" width="400px"/>
							<figcaption><code>sample_rate=9</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="supersample16.png" width="400px"/>
							<figcaption><code>sample_rate=16</code></figcaption>
						</td>
					</tr>
				</table>
			</div>
		</ol>

		<h2>Task 3: Transforms</h2>
		<ol>
			<li>A screenshot of the robot is below. I rotated and translated some of the robot's body parts in the SVG file to make it look like he is trying to balance on one leg (this was done by adding <code>g</code> tags in the SVG file).</li>
			<figure>
				<img src="robot.png" alt="Robot" style="width:50%"/>
				<figcaption>The above image is rendered at <code>sample_rate=16</code> with default settings.</figcaption>
			</figure>
		</ol>

		<h2>Task 4: Barycentric coordinates</h2>
		<ol>
			<li>The way I implemented barycentric interpolation was taking the ratios of the \(L\)-value calculations of Task 1, and using these ratios to weight the effect of each triangle corner color on every sample point in the triangle. Since the \(L\)-values represent how to the "left" or to the "right" a point is to a side of the triangle, for each vertex \(v_i\) on the triangle and a sample point \(x\), we calculate \(\frac{L(v_j,v_k,x)}{L(v_j,v_k,v_i)}\), where \(v_j\) and \(v_k\) are the other vertices (in either clockwise or counter-clockwise order), and \(L(a,b,c)=-(c_x-a_x)(b_y-a_y) + (c_y-a_y)(b_x-a_x)\). Therefore, the higher this ratio, the more proportionally close that the sample point \(x\) is to \(v_i\). Therefore, \(\alpha\), \(\beta\), and \(\gamma\) represent the ratios for each of the three vertices of the triangle, and taking the weighted average of the colors based on these ratios for each sample point gives us an effect like the following:</li>
			<figure>
				<img src="diagram.png" alt="diagram" style="width:50%"/>
				<figcaption>You can see how the closer you get to a specific corner, the more the sample points look like the closer corner's color (the above screenshot is under default settings with <code>sample_rate=16</code>).</figcaption>
			</figure>
			<li>Here is a screenshot of my color wheel:</li>
			<figure>
				<img src="wheel.png" alt="Wheel" style="width:50%"/>
				<figcaption>The above image is rendered at <code>sample_rate=1</code> with default settings.</figcaption>
			</figure>
		</ol>

		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		<ol>
			<li>To implement pixel sampling, I first calculated the barycentric coordinates for each point that is inside the triangle \((x_0,y_0),(x_1,y_1),(x_2,y_2)\) (i.e. the \(\alpha\), \(]beta\), and \(\gamma\) values). Then, I calculated the "transformation" of this barycentric coordinate into the triangle \((u_0,v_0),(u_1,v_1),(u_2,v_2)\) by calculating \(\alpha\cdot(u_0,v_0)+\beta\cdot(u_1,v_1)+\gamma\cdot(u_2,v_2)\) and up-scaling the \(x\) and \(y\)-coordinates by the width and height of the texture, respectively. This tells us which point on the <strong>texture</strong> to sample to get the corresponding color value in our final rasterized triangle. After limiting the coordinates to the size of the texture, I got the color in the following way for reach case:
			<ul>
				<li>Nearest-Neighbor: I just took the floor of the coordinates (rounded the \(x\) and \(y\) input coordinates down) and returned whatever color this was on the texture.</li>
				<li>Bilinear: I rounded the coordinates to the nearest integer coordinates and took the color values of the \(2\times 2\) square with the bottom right square being the rounded coordinate square. Then, I "lerp"-ed the true unrounded coordinate horizontally for the top two and bottom two squares separately, and then I finally lerped the resulting colors vertically to get the final color. To perform a "lerp", I calculate the following:\[\text{lerp}(A,B,p)=A_\text{color}+\frac{p}{B_\text{coordinate}-A_\text{coordinate}}(B_\text{color}-A_\text{color})\]where \(p\) and the coordinates are either \(x\) or \(y\)-coordinates.</li>
			</ul>
			</li>
			<li>I found <code>texmap/test6.svg</code> to show a strong difference. The screenshots are below. </li>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="campanile-n1.png" width="400px"/>
							<figcaption>Nearest Neighbor(<code>sample_rate=1</code>)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="campanile-n16.png" width="400px"/>
							<figcaption>Nearest Neighbor(<code>sample_rate=16</code>)</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="campanile-b1.png" width="400px"/>
							<figcaption>Bilinear(<code>sample_rate=1</code>)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="campanile-b16.png" width="400px"/>
							<figcaption>Bilinear(<code>sample_rate=16</code>)</figcaption>
						</td>
					</tr>
				</table>
			</div>
			<li>It appears that bilinear filtering performs better and the image looks significantly smoother (particularly with low sample rates) on the above images. Bilinear filtering will likely be the most advantageous when fine details in a texture have to be shown without aliasing/stark differences in colors in adjacent pixels representing the same object. With nearest-neighbor, you often do not get much of a blending of colors when rasterizing, because every sample must strictly be the exact color of the nearest pixel, and can not be the "average" of multiple pixels (assuming supersampling isn't involved yet). This leads to aliasing, such as with how there are very dark pixels right next to very light pixels in the tree on the top left image. But, with bilinear filtering, even at low sample rates, we get a lot of clarity with the leaves, because we are taking a weighted average of the color of four pixels instead of just one (preventing adjacent pixels in the letters being starkly different colors and thus reducing aliasing). But, with high sample rates, bilinear filtering and nearest-neighbor filtering look more similar, as the supersampling blends the output colors regardless of the underlying texture sampling method.</li>
		</ol>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		<ol>
			<li>In general, level sampling is an approximation of supersampling for texture mapping. More specifically, level sampling takes advantage of the fact that the mapping from a triangle on the screen to a triangle on a texture will non necessarily be one-for-one in size. Therefore, we can look at a "smaller resolution" of the texture when picking the color to return from the texture sample. First, before sampling a pixel from a texture, I created barycentric interpolations of \((x+1,y)\) and \((x,y+1)\) along with the interpolation of \((x,y)\) (we will call the transformation \((u,v)=f(x,y)\)). For calculating the level of a coordinate \((u,v)\), I approximated \(\left(\frac{du}{dx},\frac{dv}{dx}\right)\approx f(x+1,y)-f(x,y)\) and \(\left(\frac{du}{dy},\frac{dv}{dy}\right)\approx f(x,y+1)-f(x,y)\). Then, I up-scaled each \(u\)-component and \(v\)-component of the derivatives/interpolated points by the width and height of the texture, respectively. The level is then determined by:
				\[L=\log_2\left(\max\left(\sqrt{\left(\frac{du}{dx}\right)^2+\left(\frac{dv}{dx}\right)^2},\sqrt{\left(\frac{du}{dy}\right)^2+\left(\frac{dv}{dy}\right)^2}\right)\right)\]
			Now, there are two cases to consider:
			<ul>
				<li>Level-0 sampling: Nothing changes from Task 5 (I just run the respective pixel sampling function with <code>level=0</code>).</li>
				<li>Nearest Neighbor: I took \(\lfloor L\rfloor\) (and clamped it into the range of the number of layers I have), and passed this as my level to the chosen pixel sampling function.</li>
				<li>Linear Sampling: I performed pixel sampling on both the level \(l:=\lfloor L\rfloor\) and \(u:=\lfloor L\rfloor -1\). Then, I labeled the color samples \(C_l\) and \(C_u\). Then, the returned color is the lerped version of the color:
					\[C=C_l+\frac{L-l}{u-l+1}\left(C_u-C_l\right)\]
				Note that the reason for adding \(1\) to the denominator is to account for the fact that the range is geometrically \(2\) units wide, not simply the difference of the starting and ending index.</li>
			</ul>
			Once I get my desired color, I just return it as the result of my sample.
			</li>
			<li>Here are the three measurement comparisons:
				<ul>
					<li>Speed: Taking multiple samples for a pixel takes the most time, since you will need to take multiple samples for every pixel that you are trying to render. The next slowest is level sampling, which requires you to perform an extra calculation for each pixel to calculate which level the pixel is at in the texture. Finally, the fastest is pixel sampling, as we are just sampling one pixel for each input pixel when texture sampling.</li>
					<li>Memory: Taking multiple samples for a pixel will take the most memory (when texture sampling with \(k\) samples per pixel with \(n\) total pixels, we need \(\mathcal{O}(nk)\) time). Then, the next lower memory usage is for level sampling, which requires us to store some extra lower resolution textures (but since each texture is \(\frac{1}{4}\) the size of the previous texture, we actually don't use much extra space!). Finally, the most memory efficient is pixel sampling, because we are simply sampling once per each pixel, which doesn't require memory usage beyond just storing the final pixel values.</li>
					<li>Antialiasing: Pixel sampling is the worst, because we end-up getting aliasing from each pixel just being the color of the nearest neighbor in the texture (this leads to jaggies, Moire patterns, etc.). Level sampling is significantly better, as for pixels that represent larger portions of the texture, the level sampling gives us an average of the color values of multiple pixels in the texture, leading to more blurring and less aliasing. The best is taking multiple samples per pixel, as every single pixel is now the average of multiple close samples in the texture, meaning that there is more accurate and effective blurring compared to level sampling and pixel sampling.</li>
				</ul>
			</li>
			<li>
				Below are screenshots I took of a PNG I found on the internet. We can observe that not using level sampling gives us more detail, but with a lot of aliasing. But, using level sampling avoids the aliasing while sacrificing detail (which shows how level sampling is somewhat of an intermediate between supersampling and basic pixel sampling). All of the below images are generated with <code>sample_rate=1</code>.
				<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="car-zn.png" width="400px"/>
							<figcaption><code>L_ZERO,P_NEAREST</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="car-zb.png" width="400px"/>
							<figcaption><code>L_ZERO,P_LINEAR</code></figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="car-ln.png" width="400px"/>
							<figcaption><code>L_NEAREST,P_NEAREST</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="car-lb.png" width="400px"/>
							<figcaption><code>L_NEAREST,P_LINEAR</code></figcaption>
						</td>
					</tr>
				</table>
			</div>
			</li>
		</ol>
		</div>
	</body>
</html>
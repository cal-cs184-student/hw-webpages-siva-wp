<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Siva Tanikonda</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-siva-wp/hw1/index.html">cal-cs184-student.github.io/hw-webpages-siva-wp/hw1/index.html</a>
		
		<br>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw1-siva-tanikonda">github.com/cal-cs184-student/sp25-hw1-siva-tanikonda</a>

		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		In this homework, I added features to a rasterization pipeline, including triangle rasterization (with some optimizations), supersampling, transformations for SVGs, barycentric interpolation, texture sampling (with nearest-neighbor and bilinear sampling), and level sampling. In particular, what I found the most fascinating about this homework was the versatility of triangles being the smallest component in typical graphics pipelines, as finding out if points are in a shape and translating positions on one shape to positions on another corresponding shape is extremely efficient and simple with triangles being the shape you are rasterizing (especially with tricks such as the three-line test). In addition, it was interesting seeing the way SVGs differ from standard image formats (PNGs, JPEGs, etc.), and how many different ways you could balance the tradeoff of image smoothness, image accuracy, memory efficiency, and speed when rendering.

		<h2>Task 1: Drawing Single-Color Triangles</h2>
		<ol>
			<li>The first step to rasterize a triangle was to find the coordinates and bounds of the bounding box. This is done by getting the minimum and maximum \(x\)-values and \(y\)-values among all the triangle vertices. Then, I loop through every half-point within the bounding box. For each of these points \((i,j)\), I had to find which side of each triangle line the point was on. For each triangle line \([(x_0,y_0),(x_1,y_1)]\), I calculated \(L(x_0,x_1,x)=-(x-x_0)(y_1-y_0)+(y-y_0)(x_1-x_0)\). \(L=0\) means that the point is on the line, \(L<0\) means that the point is to the right of the line, and \(L>0\) means that the point is to the left of the line (we are assuming that this line is directed and infinite length). As long as all points are to the left, or all points are to the right (i.e. the side is the same for every point with respect to all three sides of the triangle), then we know that our point is within the triangle. You can assume that points exactly on a line are on either side of the line (i.e. assume that a point on a line cannot violate the requirement for the point to be in the triangle). The disregard for whether all points are to the left or all the points are to the right allows us to account for both clockwise and counter-clockwise orderings of the triangle vertices, and since points lying on the triangle sides will definitely be added, we handle points on edges properly. Then, for each sample point in the triangle, we light-up the pixel with the desired color.</li>
			<li>Since I am looping through only points within the bounding box in one-pixel increments, I only look at at most \(\mathcal{O}(n)\) points (where \(n\) is the number of pixels in the bounding box). Then, we perform simple multiplications/additions/subtractions to check if each point is within the triangle (which takes \(\mathcal{O}(1)\) time). This is no worse than performing constant-time operations on each pixel in the bounding box</li>
			<li>Here is a screenshot of <code>basic/test4.svg</code> from my rendering:</li>
			<figure>
				<img src="test4.png" alt="Test 4" style="width:50%"/>
				<figcaption>Even with edge detection, the thin corners of some triangles have breaks in them.</figcaption>
			</figure>
			<li><strong>Extra Credit</strong>: here are some things I ended-up changing/optimizing when trying to improve my naive triangle rasterization algorithm (the previous <code>basic/test4.svg</code> image was rendered with the optimized version, and the previous conceptual questions were answered based on the naive algorithm before the extra credit optimizations):
				<ul>
					<li>Reduced memory access: previously, I created two new functions: <code>calculate_l</code> and <code>point_in_triangle</code> to check the side of a line a point was on and check if a point was in a triangle, respectively. I consolidated these two functions so all the functionality is in <code>point_in_triangle</code>.</li>
					<li>Reducing search space: On each iteration of the inner loop of the sampling, I made it so that once we find a point that is no longer in the triangle after a sequence of points that were in the triangle, the inner loop breaks. This means I can just move on to the next row of the triangle without checking later pixels on the current row of the triangle.</li>
				</ul>
				Here is a table of the runtimes I observed when rendering <code>hardcore/01_degenerate_square1.svg</code> with my optimizations (timings are done with <code>chrono::high_resolution_clock</code>):
				<figure>
					<table style="border: 1px solid black;">
						<tr style="border: 1px solid black;">
							<th>Optimizations</th>
							<th>Runtime</th>
						</tr>
						<tr style="border: 1px solid black;">
							<th style="border: 1px solid black;">None</th>
							<th style="border: 1px solid black;">~75 milliseconds</th>
						</tr>
						<tr style="border: 1px solid black;">
							<th style="border: 1px solid black;">Memory Optimization</th>
							<th style="border: 1px solid black;">~37 milliseconds</th>
						</tr>
						<tr style="border: 1px solid black;">
							<th style="border: 1px solid black;">Search Space Optimization</th>
							<th style="border: 1px solid black;">~32 milliseconds</th>
						</tr>
						<tr style="border: 1px solid black;">
							<th style="border: 1px solid black;">Memory Optimization + Search Space Optimization</th>
							<th style="border: 1px solid black;">~20 milliseconds</th>
						</tr>
					</table>
				</figure>
			</li>
		</ol>
		
		<h2>Task 2: Antialiasing by Supersampling</h2>
		<ol>
			<li>Here are some implementation details/ideas to note:
			<ul>
				<li>Usefulness: Supersampling is essentially a technique where instead of taking one sample per output pixel, we take multiple samples per output pixel. This is done by sampling multiple sub-points for each point in a triangle, and displaying the average color of these samples for each pixel in the output of the rendering. This prevents aliasing in the image (and aliasing decreases further as you take more samples per pixel). This is because supersampling's averaging effect prevents large differences in colors in adjacent output pixels (i.e. it makes the image look less pixelated), and it prevents artifacts such as jaggies and the Moire pattern by adding blur during the rendering process.</li>
				<li>Data Structures: The only data structure that was modified was the <code>sample_buffer</code> array. Now, when setting the sample rate (<code>set_sample_rate()</code>) or setting the frame buffer target (<code>set_framebuffer_target()</code>), I up-scaled the size of the sample buffer by <code>sample_rate</code>. This is essentially making sure that there is an square of <code>sqrt(sample_rate)*sqrt(sample_rate)</code> "sub"-samples for each pixel (which I will later average for each individual pixel to get the final pixel colors).</li>
				<li>Algorithm: There are three aspects of the algorithm that are important:
					<ul>
						<li>Resolving to the framebuffer (<code>resolve_to_framebuffer()</code>): Here, I essentially made it so for every output pixel \(i,j\) in the frame buffer, I make the color equal the average of every color in the square \(([i\sqrt{R}, (i + 1)\sqrt{R} - 1],[j\sqrt{R}, (j+1)\sqrt{R} - 1])\) in the sample buffer, where \(R\) is the sample rate. This ensures that each output pixel is the average of the corresponding \(R\) supersamples.</li>
						<li>Triangle rasterization (<code>rasterize_triangle()</code>): I managed to essentially reuse all of the code from Task 1 by first up-scaling all of the triangle coordinates by \(\sqrt{R}\) before performing my loop. Then, in <code>rasterize_point()</code>, I clamped each point to a larger range (specifically, the width and height of the window both multiplied by \(\sqrt{R}\) to account for the larger sample buffer). Then, I changed the way I indexed into the sample buffer in <code>fill_pixel()</code> as follows to account for the larger sample buffer and up-scaled coordinates:
							\[\text{sample_buffer}[y\cdot\text{width}\cdot\sqrt{R}+x]\]
						</li>
						<li>Preventing supersampling on lines and points: To avoid having supersampling affecting the rasterization of points and lines, I added an optional boolean parameter to both <code>fill_pixel()</code> and <code>rasterize_point()</code> called <code>supersampling=false</code>. If <code>true</code>, then <code>rasterize_point()</code> and <code>fill_pixel()</code> behave as necessary for triangle supersampling to work. But, if the value is <code>false</code>, then <code>rasterize_point()</code> has its standard behavior in the skeleton code (i.e. it treats the points as being un-scaled), but <code>fill_pixel()</code> now fills every sample in the square \(([x\sqrt{R}, (x + 1)\sqrt{R} - 1],[y\sqrt{R}, (y+1)\sqrt{R} - 1])\) with the color <code>c</code> to prevent supersampling from blurring the sampled colors for lines and individual points.</li>
					</ul>
				</li>
			</ul>
			<li>The screenshots of the supersampling with different sample rates are below. The reason for the improvement in the clarity of thin parts of the image (such as corners) is that even if one of our samples is slightly off the edge of a triangle, the pixel that the sample represents will still not be white, because some other samples corresponding to the same pixel are non-white/in the triangle (thus leading to the average color not being white). This allows for more clarity/antialiasing on the corners of the triangle without issues such as breaks in the corner of the triangle due to unlucky sample positions with a low sample rate. In addition, sharp changes in color are more smooth due to the averaging effect.</li>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="supersample1.png" width="400px"/>
							<figcaption><code>sample_rate=1</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="supersample4.png" width="400px"/>
							<figcaption><code>sample_rate=4</code></figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="supersample9.png" width="400px"/>
							<figcaption><code>sample_rate=9</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="supersample16.png" width="400px"/>
							<figcaption><code>sample_rate=16</code></figcaption>
						</td>
					</tr>
				</table>
			</div>
		</ol>

		<h2>Task 3: Transforms</h2>
		<ol>
			<li>A screenshot of the robot is below. I rotated and translated some of the robot's body parts in the SVG file to make it look like he is trying to balance on one leg (this was done by adding <code>g</code> tags in the SVG file).</li>
			<figure>
				<img src="robot.png" alt="Robot" style="width:50%"/>
				<figcaption>The above image is rendered at <code>sample_rate=16</code> with default settings.</figcaption>
			</figure>
		</ol>
		
		<h2>Task 4: Barycentric coordinates</h2>
		<ol>
			<li>The way I implemented barycentric interpolation was taking the ratios of the \(L\)-value calculations of Task 1, and using these ratios to weight the effect of each triangle corner color on every sample point in the triangle. Since the \(L\)-values represent how to the "left" or to the "right" a point is to a side of the triangle, for each vertex \(v_i\) on the triangle and a sample point \(v\), we calculate \(\frac{L(v_j,v_k,v)}{L(v_j,v_k,v_i)}\), where \(v_j\) and \(v_k\) are the other vertices (in either clockwise or counter-clockwise order). Therefore, the higher this ratio, the more "proportionally close" that the sample point \(v\) is to \(v_i\). I then define three constants:
			\[\alpha=\frac{L(v_1,v_2,v)}{L(v_1,v_2,v_0)},\beta=\frac{L(v_2,v_0,v)}{L(v_2,v_0,v_1)},\gamma=1-\alpha-\beta\] Then, I define the color of the sample at \(v\) to be the weighted average of the colors of the three triangle vertices as follows:\[\alpha\cdot C_0+\beta\cdot C_1+\gamma\cdot C_2\]Here is the output of Barycentric interpolation using my code that implements the outlined algorithm (there is a red, green, and blue corner on the triangle that I am interpolating):</li>
			<figure>
				<img src="diagram.png" alt="diagram" style="width:50%"/>
				<figcaption>You can see how the closer you get to a specific corner, the more the sample points look like the closer corner's color (the above screenshot is under default settings with <code>sample_rate=16</code>).</figcaption>
			</figure>
			<li>Here is a screenshot of my color wheel:</li>
			<figure>
				<img src="wheel.png" alt="Wheel" style="width:50%"/>
				<figcaption>The above image is rendered at <code>sample_rate=1</code> with default settings.</figcaption>
			</figure>
		</ol>

		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		<ol>
			<li>To implement pixel sampling, I first calculated the barycentric coordinates for each point that is inside the triangle \((x_0,y_0),(x_1,y_1),(x_2,y_2)\) (i.e. the \(\alpha\), \(\beta\), and \(\gamma\) values with respect to the final output triangle, not the texture triangle). Then, I calculated the "transformation" of this barycentric coordinate into the triangle \((u_0,v_0),(u_1,v_1),(u_2,v_2)\) by calculating: \[(u,v)=\alpha\cdot(u_0,v_0)+\beta\cdot(u_1,v_1)+\gamma\cdot(u_2,v_2)\]This tells us which point on the <strong>texture</strong> corresponds to the pixel we want to sample on the final output triangle. Then, my textured triangle rasterizer calls the <code>sample()</code> function in the texture. The <code>sample()</code> function first up-scales the \((u,v)\)-point according to the width and height of the texture and clamps the coordinate to the range of the indices of the texture array. Then, based on the type of pixel sampling, we do one of the following when texture sampling:
			<ul>
				<li>Nearest-Neighbor: I just took the floor of the \((u,v)\) coordinates and returned whatever color this was on the texture (i.e. we just pick the closest point to the floating-point coordinate that we are trying to smaple).</li>
				<li>Bilinear: I rounded the coordinates to the nearest integer pixel index (i.e. \((\text{round}(u),\text{round}(v))\)) and took the color values of the following pixels on the texture: \(a=(\text{round}(u)-1,\text{round}(v)-1),b=(\text{round}(u)-1,\text{round}(v))\), \(c=(\text{round}(u),\text{round}(v)-1)\), \(d=(\text{round}(u),\text{round}(v))\). We now define the "lerp" operation as follows for two pixels \(p\) and \(q\) and scalar float \(t\):\[\text{lerp}(C_1,C_2,p,q,t)=C_1+\frac{t}{q-p+1}(C_2-C_1)\] where the \(C_i\)s are colors. Then, I calculate the following lerps: \(C_\text{up}=\text{lerp}(C_a,C_c,a_x,c_x,u)\), \(C_\text{down}=\text{lerp}(C_b,C_d,b_x,d_x,u)\), \(C=\text{lerp}(C_\text{up},C_\text{down},a_y,b_y,v)\) (\(C\) is our final output color). Essentially, Bilinear interpolation is a "softer" method of pixel sampling for textures, where we can take something similar to a weighted average of four pixel values to determine the color of one sample. The lerp operation also ensures that the colors are accurate and that the blurring is not uniform, but rather accentuates certain details through taking into account the proximity of each sample point to each of the four pixels.</li>
			</ul>
			</li>
			<li>I found <code>texmap/test6.svg</code> to show a strong difference. The screenshots are below. </li>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="campanile-n1.png" width="400px"/>
							<figcaption>Nearest Neighbor(<code>sample_rate=1</code>)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="campanile-n16.png" width="400px"/>
							<figcaption>Nearest Neighbor(<code>sample_rate=16</code>)</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="campanile-b1.png" width="400px"/>
							<figcaption>Bilinear(<code>sample_rate=1</code>)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="campanile-b16.png" width="400px"/>
							<figcaption>Bilinear(<code>sample_rate=16</code>)</figcaption>
						</td>
					</tr>
				</table>
			</div>
			<li>It appears that bilinear filtering performs better with respect to antialiasing and the image looks significantly smoother (particularly with low sample rates). Bilinear filtering will likely be the most advantageous when fine details in a texture have to be shown without aliasing/stark differences in colors in adjacent pixels representing the same object. With nearest-neighbor, you do not get a blending of colors when rasterizing, because every sample must strictly be the exact color of the nearest pixel, and can not be the "average" of multiple pixels (assuming supersampling isn't involved yet). This leads to aliasing, such as with how there are very dark pixels right next to very light pixels in the tree on the top left image. But, with bilinear filtering, even at low sample rates, we get a lot of smoothness with the edges of the leaves, because we are taking a weighted average of the color of four pixels instead of just one (preventing adjacent pixels in the letters being starkly different colors and thus reducing aliasing). But, with high sample rates, bilinear filtering and nearest-neighbor filtering look quite similar, as the supersampling blends the output colors regardless of the underlying texture sampling method.</li>
		</ol>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		<ol>
			<li>In general, level sampling is an approximation of supersampling for texture mapping. More specifically, level sampling takes advantage of the fact that the mapping from a triangle in the final output to a triangle on a texture will non necessarily be one-to-one in size. Therefore, if the triangle in the texture is larger than the corresponding triangle in the output frame buffer, we can look at a "smaller resolution" of the texture when picking the color to return from the texture sample (this is essentially a way to "smoothen" the image by implicitly averaging the color of pixels without using much compute/storage). First, before sampling a pixel from a texture, we create barycentric interpolations of \((x+1,y)\) and \((x,y+1)\), which we will call \((u_x,v_x)\) and \((u_y,v_y)\), respectively. I then approximated \(\left(\frac{du}{dx},\frac{dv}{dx}\right)\approx (u_x-u,v_x-v)\) and \(\left(\frac{du}{dy},\frac{dv}{dy}\right)\approx (u_y-u,v_y-v)\). Then, I up-scaled each \(u\)-component and \(v\)-component of the derivatives and interpolated points by the width and height of the texture. The level is then determined by:
				\[L=\log_2\left(\max\left(\sqrt{\left(\frac{du}{dx}\right)^2+\left(\frac{dv}{dx}\right)^2},\sqrt{\left(\frac{du}{dy}\right)^2+\left(\frac{dv}{dy}\right)^2}\right)\right)\]
			Now, there are three cases to consider:
			<ul>
				<li>Level-0 sampling: Nothing changes from Task 5 (I just run the respective pixel sampling function with <code>level=0</code>).</li>
				<li>Nearest Neighbor: I took \(\lfloor L\rfloor\) (and clamped it into the range of the number of layers I have), and passed this as my level to the chosen pixel sampling function.</li>
				<li>Linear Sampling: I performed pixel sampling on both the level \(a:=\text{round}(L)-1\) and \(b:=\text{round}(L)\). Then, I labeled the color samples \(C_a\) and \(C_b\). Then, the returned color is the lerped version of the color:
					\[C=C_a+\frac{L-a}{b-a+1}\left(C_b-C_a\right)\]
				Note that the reason for adding \(1\) to the denominator is to account for the fact that the range is geometrically \(2\) units wide, not simply the difference of the starting and ending index.</li>
			</ul>
			Once I get my desired color, I just return it as the result of my sample.
			</li>
			<li>Here are the three measurement comparisons:
				<ul>
					<li>Speed: Taking multiple samples for a pixel takes the most time, since you will need to take multiple samples for every pixel that you are trying to render. The next slowest is level sampling, which requires you to perform an extra calculation for each pixel to calculate which level the pixel is at in the texture. Finally, the fastest is pixel sampling, as we are just sampling one texture pixel for each input pixel when texture sampling.</li>
					<li>Memory: Taking multiple samples for a pixel will take the most memory (when texture sampling with \(k\) samples per pixel with \(n\) total pixels, we need \(\mathcal{O}(nk)\) space). Then, the next lower memory usage is for level sampling, which requires us to store some extra lower resolution textures (but since each texture is \(\frac{1}{4}\) the size of the previous texture, we actually don't use much extra space!). Finally, the most memory efficient is pixel sampling, because we are simply sampling once per each pixel, which doesn't require memory usage beyond just storing the final pixel values.</li>
					<li>Antialiasing Power: Pixel sampling is the worst, because we end-up getting aliasing from each pixel just being the color of the nearest neighbor in the texture (this leads to jaggies, Moire patterns, etc.). Level sampling is better, as for pixels that represent larger portions of the texture, the level sampling gives us an average of the color values of multiple pixels in the texture, leading to more blurring and less aliasing. But, the best is taking multiple samples per pixel, as every single pixel is now the average of multiple close samples in the texture, meaning that there is more accurate and effective blurring compared to level sampling and pixel sampling.</li>
				</ul>
			</li>
			<li>
				Below are screenshots I took of a PNG I found on the internet. We can observe that not using level sampling gives us more detail, but with a lot of aliasing. But, using level sampling avoids the aliasing while sacrificing detail (which shows how level sampling is somewhat of an intermediate between supersampling and basic pixel sampling). All of the below images are generated with <code>sample_rate=1</code>.
				<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="car-zn.png" width="400px"/>
							<figcaption><code>L_ZERO,P_NEAREST</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="car-zb.png" width="400px"/>
							<figcaption><code>L_ZERO,P_LINEAR</code></figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="car-ln.png" width="400px"/>
							<figcaption><code>L_NEAREST,P_NEAREST</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="car-lb.png" width="400px"/>
							<figcaption><code>L_NEAREST,P_LINEAR</code></figcaption>
						</td>
					</tr>
				</table>
			</div>
			</li>
		</ol>
		</div>
	</body>
</html>